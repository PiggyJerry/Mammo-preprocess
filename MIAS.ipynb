{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed mdb001 for Train set\n",
      "Processed mdb002 for Train set\n",
      "Processed mdb003 for Train set\n",
      "Processed mdb004 for Train set\n",
      "Processed mdb005 for Train set\n",
      "Processed mdb005 for Train set\n",
      "Processed mdb006 for Train set\n",
      "Processed mdb007 for Train set\n",
      "Processed mdb008 for Train set\n",
      "Processed mdb009 for Train set\n",
      "Processed mdb010 for Train set\n",
      "Processed mdb011 for Train set\n",
      "Processed mdb012 for Train set\n",
      "Processed mdb013 for Train set\n",
      "Processed mdb014 for Train set\n",
      "Processed mdb016 for Train set\n",
      "Processed mdb018 for Train set\n",
      "Processed mdb019 for Train set\n",
      "Processed mdb020 for Train set\n",
      "Processed mdb022 for Train set\n",
      "Processed mdb023 for Train set\n",
      "Processed mdb024 for Train set\n",
      "Processed mdb025 for Train set\n",
      "Processed mdb026 for Train set\n",
      "Processed mdb027 for Train set\n",
      "Processed mdb028 for Train set\n",
      "Processed mdb029 for Train set\n",
      "Processed mdb031 for Train set\n",
      "Processed mdb033 for Train set\n",
      "Processed mdb035 for Train set\n",
      "Processed mdb037 for Train set\n",
      "Processed mdb039 for Train set\n",
      "Processed mdb040 for Train set\n",
      "Processed mdb041 for Train set\n",
      "Processed mdb042 for Train set\n",
      "Processed mdb043 for Train set\n",
      "Processed mdb044 for Train set\n",
      "Processed mdb045 for Train set\n",
      "Processed mdb047 for Train set\n",
      "Processed mdb048 for Train set\n",
      "Processed mdb049 for Train set\n",
      "Processed mdb050 for Train set\n",
      "Processed mdb051 for Train set\n",
      "Processed mdb053 for Train set\n",
      "Processed mdb054 for Train set\n",
      "Processed mdb055 for Train set\n",
      "Processed mdb056 for Train set\n",
      "Processed mdb057 for Train set\n",
      "Processed mdb058 for Train set\n",
      "Processed mdb061 for Train set\n",
      "Processed mdb062 for Train set\n",
      "Processed mdb063 for Train set\n",
      "Processed mdb064 for Train set\n",
      "Processed mdb065 for Train set\n",
      "Processed mdb067 for Train set\n",
      "Processed mdb068 for Train set\n",
      "Processed mdb070 for Train set\n",
      "Processed mdb072 for Train set\n",
      "Processed mdb073 for Train set\n",
      "Processed mdb074 for Train set\n",
      "Processed mdb076 for Train set\n",
      "Processed mdb077 for Train set\n",
      "Processed mdb078 for Train set\n",
      "Processed mdb079 for Train set\n",
      "Processed mdb080 for Train set\n",
      "Processed mdb081 for Train set\n",
      "Processed mdb082 for Train set\n",
      "Processed mdb083 for Train set\n",
      "Processed mdb084 for Train set\n",
      "Processed mdb086 for Train set\n",
      "Processed mdb087 for Train set\n",
      "Processed mdb088 for Train set\n",
      "Processed mdb089 for Train set\n",
      "Processed mdb090 for Train set\n",
      "Processed mdb091 for Train set\n",
      "Processed mdb093 for Train set\n",
      "Processed mdb095 for Train set\n",
      "Processed mdb096 for Train set\n",
      "Processed mdb098 for Train set\n",
      "Processed mdb099 for Train set\n",
      "Processed mdb100 for Train set\n",
      "Processed mdb101 for Train set\n",
      "Processed mdb102 for Train set\n",
      "Processed mdb103 for Train set\n",
      "Processed mdb104 for Train set\n",
      "Processed mdb106 for Train set\n",
      "Processed mdb107 for Train set\n",
      "Processed mdb108 for Train set\n",
      "Processed mdb109 for Train set\n",
      "Processed mdb111 for Train set\n",
      "Processed mdb112 for Train set\n",
      "Processed mdb113 for Train set\n",
      "Processed mdb115 for Train set\n",
      "Processed mdb117 for Train set\n",
      "Processed mdb118 for Train set\n",
      "Processed mdb119 for Train set\n",
      "Processed mdb120 for Train set\n",
      "Processed mdb121 for Train set\n",
      "Processed mdb122 for Train set\n",
      "Processed mdb123 for Train set\n",
      "Processed mdb124 for Train set\n",
      "Processed mdb125 for Train set\n",
      "Processed mdb126 for Train set\n",
      "Processed mdb127 for Train set\n",
      "Processed mdb128 for Train set\n",
      "Processed mdb129 for Train set\n",
      "Processed mdb130 for Train set\n",
      "Processed mdb131 for Train set\n",
      "Processed mdb132 for Train set\n",
      "Processed mdb132 for Train set\n",
      "Processed mdb133 for Train set\n",
      "Processed mdb134 for Train set\n",
      "Processed mdb136 for Train set\n",
      "Processed mdb137 for Train set\n",
      "Processed mdb138 for Train set\n",
      "Processed mdb139 for Train set\n",
      "Processed mdb140 for Train set\n",
      "Processed mdb141 for Train set\n",
      "Processed mdb142 for Train set\n",
      "Processed mdb143 for Train set\n",
      "Processed mdb144 for Train set\n",
      "Processed mdb144 for Train set\n",
      "Processed mdb145 for Train set\n",
      "Processed mdb146 for Train set\n",
      "Processed mdb147 for Train set\n",
      "Processed mdb149 for Train set\n",
      "Processed mdb150 for Train set\n",
      "Processed mdb151 for Train set\n",
      "Processed mdb152 for Train set\n",
      "Processed mdb153 for Train set\n",
      "Processed mdb154 for Train set\n",
      "Processed mdb155 for Train set\n",
      "Processed mdb156 for Train set\n",
      "Processed mdb157 for Train set\n",
      "Processed mdb158 for Train set\n",
      "Processed mdb160 for Train set\n",
      "Processed mdb161 for Train set\n",
      "Processed mdb164 for Train set\n",
      "Processed mdb165 for Train set\n",
      "Processed mdb166 for Train set\n",
      "Processed mdb167 for Train set\n",
      "Processed mdb168 for Train set\n",
      "Processed mdb169 for Train set\n",
      "Processed mdb171 for Train set\n",
      "Processed mdb172 for Train set\n",
      "Processed mdb173 for Train set\n",
      "Processed mdb174 for Train set\n",
      "Processed mdb175 for Train set\n",
      "Processed mdb177 for Train set\n",
      "Processed mdb178 for Train set\n",
      "Processed mdb179 for Train set\n",
      "Processed mdb181 for Train set\n",
      "Processed mdb182 for Train set\n",
      "Processed mdb183 for Train set\n",
      "Processed mdb184 for Train set\n",
      "Processed mdb186 for Train set\n",
      "Processed mdb187 for Train set\n",
      "Processed mdb188 for Train set\n",
      "Processed mdb189 for Train set\n",
      "Processed mdb190 for Train set\n",
      "Processed mdb193 for Train set\n",
      "Processed mdb194 for Train set\n",
      "Processed mdb195 for Train set\n",
      "Processed mdb196 for Train set\n",
      "Processed mdb198 for Train set\n",
      "Processed mdb199 for Train set\n",
      "Processed mdb200 for Train set\n",
      "Processed mdb202 for Train set\n",
      "Processed mdb204 for Train set\n",
      "Processed mdb205 for Train set\n",
      "Processed mdb207 for Train set\n",
      "Processed mdb209 for Train set\n",
      "Processed mdb210 for Train set\n",
      "Processed mdb211 for Train set\n",
      "Processed mdb212 for Train set\n",
      "Processed mdb213 for Train set\n",
      "Processed mdb214 for Train set\n",
      "Processed mdb215 for Train set\n",
      "Processed mdb216 for Train set\n",
      "Processed mdb218 for Train set\n",
      "Processed mdb220 for Train set\n",
      "Processed mdb221 for Train set\n",
      "Processed mdb224 for Train set\n",
      "Processed mdb225 for Train set\n",
      "Processed mdb226 for Train set\n",
      "Processed mdb226 for Train set\n",
      "Processed mdb226 for Train set\n",
      "Processed mdb227 for Train set\n",
      "Processed mdb228 for Train set\n",
      "Processed mdb229 for Train set\n",
      "Processed mdb230 for Train set\n",
      "Processed mdb231 for Train set\n",
      "Processed mdb232 for Train set\n",
      "Processed mdb233 for Train set\n",
      "Processed mdb234 for Train set\n",
      "Processed mdb235 for Train set\n",
      "Processed mdb236 for Train set\n",
      "Processed mdb237 for Train set\n",
      "Processed mdb238 for Train set\n",
      "Processed mdb239 for Train set\n",
      "Processed mdb239 for Train set\n",
      "Processed mdb240 for Train set\n",
      "Processed mdb241 for Train set\n",
      "Processed mdb242 for Train set\n",
      "Processed mdb245 for Train set\n",
      "Processed mdb246 for Train set\n",
      "Processed mdb247 for Train set\n",
      "Processed mdb248 for Train set\n",
      "Processed mdb249 for Train set\n",
      "Processed mdb249 for Train set\n",
      "Processed mdb250 for Train set\n",
      "Processed mdb251 for Train set\n",
      "Processed mdb253 for Train set\n",
      "Processed mdb254 for Train set\n",
      "Processed mdb255 for Train set\n",
      "Processed mdb258 for Train set\n",
      "Processed mdb259 for Train set\n",
      "Processed mdb260 for Train set\n",
      "Processed mdb262 for Train set\n",
      "Processed mdb263 for Train set\n",
      "Processed mdb264 for Train set\n",
      "Processed mdb265 for Train set\n",
      "Processed mdb267 for Train set\n",
      "Processed mdb268 for Train set\n",
      "Processed mdb269 for Train set\n",
      "Processed mdb270 for Train set\n",
      "Processed mdb271 for Train set\n",
      "Processed mdb272 for Train set\n",
      "Processed mdb273 for Train set\n",
      "Processed mdb274 for Train set\n",
      "Processed mdb275 for Train set\n",
      "Processed mdb278 for Train set\n",
      "Processed mdb279 for Train set\n",
      "Processed mdb280 for Train set\n",
      "Processed mdb281 for Train set\n",
      "Processed mdb282 for Train set\n",
      "Processed mdb283 for Train set\n",
      "Processed mdb284 for Train set\n",
      "Processed mdb285 for Train set\n",
      "Processed mdb287 for Train set\n",
      "Processed mdb288 for Train set\n",
      "Processed mdb289 for Train set\n",
      "Processed mdb291 for Train set\n",
      "Processed mdb292 for Train set\n",
      "Processed mdb294 for Train set\n",
      "Processed mdb295 for Train set\n",
      "Processed mdb296 for Train set\n",
      "Processed mdb297 for Train set\n",
      "Processed mdb298 for Train set\n",
      "Processed mdb299 for Train set\n",
      "Processed mdb300 for Train set\n",
      "Processed mdb302 for Train set\n",
      "Processed mdb303 for Train set\n",
      "Processed mdb304 for Train set\n",
      "Processed mdb308 for Train set\n",
      "Processed mdb309 for Train set\n",
      "Processed mdb310 for Train set\n",
      "Processed mdb311 for Train set\n",
      "Processed mdb312 for Train set\n",
      "Processed mdb313 for Train set\n",
      "Processed mdb317 for Train set\n",
      "Processed mdb318 for Train set\n",
      "Processed mdb321 for Train set\n",
      "Processed mdb322 for Train set\n",
      "Processed mdb015 for Test set\n",
      "Processed mdb017 for Test set\n",
      "Processed mdb021 for Test set\n",
      "Processed mdb030 for Test set\n",
      "Processed mdb032 for Test set\n",
      "Processed mdb034 for Test set\n",
      "Processed mdb036 for Test set\n",
      "Processed mdb038 for Test set\n",
      "Processed mdb046 for Test set\n",
      "Processed mdb052 for Test set\n",
      "Processed mdb059 for Test set\n",
      "Processed mdb060 for Test set\n",
      "Processed mdb066 for Test set\n",
      "Processed mdb069 for Test set\n",
      "Processed mdb071 for Test set\n",
      "Processed mdb075 for Test set\n",
      "Processed mdb085 for Test set\n",
      "Processed mdb092 for Test set\n",
      "Processed mdb094 for Test set\n",
      "Processed mdb097 for Test set\n",
      "Processed mdb105 for Test set\n",
      "Processed mdb110 for Test set\n",
      "Processed mdb114 for Test set\n",
      "Processed mdb116 for Test set\n",
      "Processed mdb135 for Test set\n",
      "Processed mdb148 for Test set\n",
      "Processed mdb159 for Test set\n",
      "Processed mdb162 for Test set\n",
      "Processed mdb163 for Test set\n",
      "Processed mdb170 for Test set\n",
      "Processed mdb176 for Test set\n",
      "Processed mdb180 for Test set\n",
      "Processed mdb185 for Test set\n",
      "Processed mdb191 for Test set\n",
      "Processed mdb192 for Test set\n",
      "Processed mdb197 for Test set\n",
      "Processed mdb201 for Test set\n",
      "Processed mdb203 for Test set\n",
      "Processed mdb206 for Test set\n",
      "Processed mdb208 for Test set\n",
      "Processed mdb217 for Test set\n",
      "Processed mdb219 for Test set\n",
      "Processed mdb222 for Test set\n",
      "Processed mdb223 for Test set\n",
      "Processed mdb223 for Test set\n",
      "Processed mdb243 for Test set\n",
      "Processed mdb244 for Test set\n",
      "Processed mdb252 for Test set\n",
      "Processed mdb256 for Test set\n",
      "Processed mdb257 for Test set\n",
      "Processed mdb261 for Test set\n",
      "Processed mdb266 for Test set\n",
      "Processed mdb276 for Test set\n",
      "Processed mdb277 for Test set\n",
      "Processed mdb286 for Test set\n",
      "Processed mdb290 for Test set\n",
      "Processed mdb293 for Test set\n",
      "Processed mdb301 for Test set\n",
      "Processed mdb305 for Test set\n",
      "Processed mdb306 for Test set\n",
      "Processed mdb307 for Test set\n",
      "Processed mdb314 for Test set\n",
      "Processed mdb315 for Test set\n",
      "Processed mdb316 for Test set\n",
      "Processed mdb319 for Test set\n",
      "Processed mdb320 for Test set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocess(img):\n",
    "    # 找到原图中所有为0的行和列\n",
    "    rows_to_keep = np.any(img != 0, axis=1)\n",
    "    cols_to_keep = np.any(img != 0, axis=0)\n",
    "\n",
    "    # 删除原图中全部为0的行和列\n",
    "    img = img[rows_to_keep][:, cols_to_keep]\n",
    "\n",
    "    return img\n",
    "\n",
    "# 定义路径\n",
    "TXT_PATH = '/Volumes/图图/MIAS/archive/Info.txt'\n",
    "PGM_PATH = '/Volumes/图图/MIAS/archive/all-mias'\n",
    "OUTPUT_BASE_PATH = '/Volumes/图图/MIAS/archive/image-classification'\n",
    "\n",
    "# 读取TXT文件\n",
    "with open(TXT_PATH, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# 跳过标题行\n",
    "lines = lines[1:]\n",
    "\n",
    "refnums = [line.split()[0] for line in lines]\n",
    "unique_refnums = list(set(refnums))\n",
    "\n",
    "# 将去重后的 refnum 按8:2分为训练集和测试集\n",
    "train_refnums, test_refnums = train_test_split(unique_refnums, test_size=0.2, random_state=42)\n",
    "\n",
    "# 根据去重后的 refnum 划分原始数据集\n",
    "train_lines = [line for line in lines if line.split()[0] in train_refnums]\n",
    "test_lines = [line for line in lines if line.split()[0] in test_refnums]\n",
    "\n",
    "def process_and_save(lines, set_type):\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        refnum = parts[0]\n",
    "        bg = str(parts[1]).replace(' ','')\n",
    "        # cls = parts[2]\n",
    "        # severity = parts[3] if len(parts) > 3 else 'N'\n",
    "\n",
    "        # 读取PGM文件\n",
    "        pgm_file = os.path.join(PGM_PATH, refnum + '.pgm')\n",
    "        if os.path.exists(pgm_file):\n",
    "            img = cv2.imread(pgm_file, cv2.IMREAD_GRAYSCALE)\n",
    "            img = preprocess(img)\n",
    "            img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "            # 创建输出目录\n",
    "            output_dir = os.path.join(OUTPUT_BASE_PATH, set_type, refnum)\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "\n",
    "            # 保存预处理后的图像为JPEG格式\n",
    "            jpg_output_path = os.path.join(output_dir, 'img.jpg')\n",
    "            cv2.imwrite(jpg_output_path, img)\n",
    "\n",
    "            # 保存标签为NumPy文件字典\n",
    "            info = {\n",
    "                'background': bg\n",
    "                # 'class': cls,\n",
    "                # 'severity': severity\n",
    "            }\n",
    "            npy_path = os.path.join(output_dir, 'info_dict.npy')\n",
    "            np.save(npy_path, info)\n",
    "\n",
    "            print(f\"Processed {refnum} for {set_type} set\")\n",
    "        else:\n",
    "            print(f\"PGM file for {refnum} not found.\")\n",
    "\n",
    "# 处理并保存训练集和测试集\n",
    "process_and_save(train_lines, 'Train')\n",
    "process_and_save(test_lines, 'Test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cropped-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed mdb130 for Train set\n",
      "Processed mdb025 for Train set\n",
      "Processed mdb032 for Train set\n",
      "Processed mdb188 for Train set\n",
      "Processed mdb256 for Train set\n",
      "Processed mdb090 for Train set\n",
      "Processed mdb179 for Train set\n",
      "Processed mdb081 for Train set\n",
      "Processed mdb115 for Train set\n",
      "Processed mdb152 for Train set\n",
      "Processed mdb209 for Train set\n",
      "Processed mdb102 for Train set\n",
      "Processed mdb170 for Train set\n",
      "Processed mdb191 for Train set\n",
      "Processed mdb019 for Train set\n",
      "Processed mdb107 for Train set\n",
      "Processed mdb274 for Train set\n",
      "Processed mdb184 for Train set\n",
      "Processed mdb097 for Train set\n",
      "Processed mdb134 for Train set\n",
      "Processed mdb213 for Train set\n",
      "Processed mdb012 for Train set\n",
      "Processed mdb202 for Train set\n",
      "Processed mdb181 for Train set\n",
      "Processed mdb121 for Train set\n",
      "Processed mdb142 for Train set\n",
      "Processed mdb111 for Train set\n",
      "Processed mdb058 for Train set\n",
      "Processed mdb178 for Train set\n",
      "Processed mdb110 for Train set\n",
      "Processed mdb214 for Train set\n",
      "Processed mdb015 for Train set\n",
      "Processed mdb127 for Train set\n",
      "Processed mdb271 for Train set\n",
      "Processed mdb204 for Train set\n",
      "Processed mdb095 for Train set\n",
      "Processed mdb072 for Train set\n",
      "Processed mdb227 for Train set\n",
      "Processed mdb249 for Train set\n",
      "Processed mdb091 for Train set\n",
      "Processed mdb017 for Train set\n",
      "Processed mdb028 for Train set\n",
      "Processed mdb212 for Train set\n",
      "Processed mdb005 for Train set\n",
      "Processed mdb063 for Train set\n",
      "Processed mdb120 for Train set\n",
      "Processed mdb226 for Train set\n",
      "Processed mdb013 for Train set\n",
      "Processed mdb199 for Train set\n",
      "Processed mdb241 for Train set\n",
      "Processed mdb226 for Train set\n",
      "Processed mdb150 for Train set\n",
      "Processed mdb144 for Train set\n",
      "Processed mdb264 for Train set\n",
      "Processed mdb132 for Train set\n",
      "Processed mdb207 for Train set\n",
      "Processed mdb167 for Train set\n",
      "Processed mdb290 for Train set\n",
      "Processed mdb206 for Train set\n",
      "Processed mdb312 for Train set\n",
      "Processed mdb125 for Train set\n",
      "Processed mdb160 for Train set\n",
      "Processed mdb141 for Train set\n",
      "Processed mdb240 for Train set\n",
      "Processed mdb158 for Train set\n",
      "Processed mdb198 for Train set\n",
      "Processed mdb105 for Train set\n",
      "Processed mdb267 for Train set\n",
      "Processed mdb163 for Train set\n",
      "Processed mdb171 for Train set\n",
      "Processed mdb239 for Train set\n",
      "Processed mdb117 for Train set\n",
      "Processed mdb099 for Train set\n",
      "Processed mdb249 for Train set\n",
      "Processed mdb002 for Train set\n",
      "Processed mdb145 for Train set\n",
      "Processed mdb080 for Train set\n",
      "Processed mdb005 for Train set\n",
      "Processed mdb083 for Train set\n",
      "Processed mdb248 for Train set\n",
      "Processed mdb239 for Train set\n",
      "Processed mdb219 for Train set\n",
      "Processed mdb253 for Train set\n",
      "Processed mdb195 for Train set\n",
      "Processed mdb218 for Train set\n",
      "Processed mdb211 for Train set\n",
      "Processed mdb315 for Train set\n",
      "Processed mdb075 for Train set\n",
      "Processed mdb165 for Train set\n",
      "Processed mdb190 for Train set\n",
      "Processed mdb252 for Train set\n",
      "Processed mdb030 for Train set\n",
      "Processed mdb226 for Train set\n",
      "Processed mdb144 for Train set\n",
      "Processed mdb244 for Train set\n",
      "Processed mdb155 for Test set\n",
      "Processed mdb223 for Test set\n",
      "Processed mdb010 for Test set\n",
      "Processed mdb132 for Test set\n",
      "Processed mdb092 for Test set\n",
      "Processed mdb314 for Test set\n",
      "Processed mdb186 for Test set\n",
      "Processed mdb021 for Test set\n",
      "Processed mdb223 for Test set\n",
      "Processed mdb193 for Test set\n",
      "Processed mdb069 for Test set\n",
      "Processed mdb270 for Test set\n",
      "Processed mdb023 for Test set\n",
      "Processed mdb236 for Test set\n",
      "Processed mdb126 for Test set\n",
      "Processed mdb104 for Test set\n",
      "Processed mdb222 for Test set\n",
      "Processed mdb001 for Test set\n",
      "Processed mdb238 for Test set\n",
      "Processed mdb265 for Test set\n",
      "Processed mdb175 for Test set\n",
      "Processed mdb124 for Test set\n",
      "Processed mdb231 for Test set\n",
      "Processed mdb148 for Test set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def crop_and_save(img, x, y, radius, output_path):\n",
    "    # 确保裁剪区域不超出图像边界\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    radius = int(radius)\n",
    "    x1 = max(x - radius, 0)\n",
    "    y1 = max(y - radius, 0)\n",
    "    x2 = min(x + radius, img.shape[1])\n",
    "    y2 = min(y + radius, img.shape[0])\n",
    "\n",
    "    # 裁剪图像\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "    cropped_img = cv2.normalize(cropped_img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "    # 保存裁剪后的图像\n",
    "    cv2.imwrite(output_path, cropped_img)\n",
    "\n",
    "\n",
    "# 定义路径\n",
    "TXT_PATH = '/Volumes/图图/MIAS/archive/Info.txt'\n",
    "PGM_PATH = '/Volumes/图图/MIAS/archive/all-mias'\n",
    "OUTPUT_BASE_PATH = '/Volumes/图图/MIAS/archive/cropped-classification'\n",
    "\n",
    "# 读取TXT文件\n",
    "with open(TXT_PATH, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# 跳过标题行\n",
    "lines = lines[1:]\n",
    "lines = [line for line in lines if len(line.split()) > 4]\n",
    "\n",
    "train_lines, test_lines = train_test_split(lines, test_size=0.2, random_state=42)\n",
    "\n",
    "def process_and_save(lines, set_type):\n",
    "    refnum_counter = {}\n",
    "    for line in lines:\n",
    "        # print(line)\n",
    "        parts = line.split()\n",
    "        refnum = parts[0]\n",
    "        # bg = parts[1]\n",
    "        cls = str(parts[2]).replace(' ','')\n",
    "        severity = str(parts[3]).replace(' ','')\n",
    "        x = parts[4]\n",
    "        y = parts[5]\n",
    "        radius = parts[6]\n",
    "        \n",
    "        if refnum in refnum_counter:\n",
    "            refnum_counter[refnum] += 1\n",
    "        else:\n",
    "            refnum_counter[refnum] = 1\n",
    "        refnum_with_suffix = f\"{refnum}_{refnum_counter[refnum]}\"\n",
    "\n",
    "        # 读取PGM文件\n",
    "        pgm_file = os.path.join(PGM_PATH, refnum + '.pgm')\n",
    "        if os.path.exists(pgm_file):\n",
    "            img = cv2.imread(pgm_file, cv2.IMREAD_GRAYSCALE)\n",
    "            # img = preprocess(img)\n",
    "            # img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "            # 创建输出目录\n",
    "            output_dir = os.path.join(OUTPUT_BASE_PATH, set_type, refnum_with_suffix)\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "\n",
    "            jpg_output_path = os.path.join(output_dir, 'img.jpg')\n",
    "            crop_and_save(img, x, y, radius, jpg_output_path)\n",
    "\n",
    "            # 保存标签为NumPy文件字典\n",
    "            info = {\n",
    "                # 'background': bg\n",
    "                'class': cls,\n",
    "                'severity': severity\n",
    "            }\n",
    "            npy_path = os.path.join(output_dir, 'info_dict.npy')\n",
    "            np.save(npy_path, info)\n",
    "\n",
    "            print(f\"Processed {refnum} for {set_type} set\")\n",
    "        else:\n",
    "            print(f\"PGM file for {refnum} not found.\")\n",
    "\n",
    "# 处理并保存训练集和测试集\n",
    "process_and_save(train_lines, 'Train')\n",
    "process_and_save(test_lines, 'Test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed mdb130 for Train set\n",
      "Processed mdb025 for Train set\n",
      "Processed mdb032 for Train set\n",
      "Processed mdb188 for Train set\n",
      "Processed mdb256 for Train set\n",
      "Processed mdb090 for Train set\n",
      "Processed mdb179 for Train set\n",
      "Processed mdb081 for Train set\n",
      "Processed mdb115 for Train set\n",
      "Processed mdb152 for Train set\n",
      "Processed mdb209 for Train set\n",
      "Processed mdb102 for Train set\n",
      "Processed mdb170 for Train set\n",
      "Processed mdb191 for Train set\n",
      "Processed mdb019 for Train set\n",
      "Processed mdb107 for Train set\n",
      "Processed mdb274 for Train set\n",
      "Processed mdb184 for Train set\n",
      "Processed mdb097 for Train set\n",
      "Processed mdb134 for Train set\n",
      "Processed mdb213 for Train set\n",
      "Processed mdb012 for Train set\n",
      "Processed mdb202 for Train set\n",
      "Processed mdb181 for Train set\n",
      "Processed mdb121 for Train set\n",
      "Processed mdb142 for Train set\n",
      "Processed mdb111 for Train set\n",
      "Processed mdb058 for Train set\n",
      "Processed mdb178 for Train set\n",
      "Processed mdb110 for Train set\n",
      "Processed mdb214 for Train set\n",
      "Processed mdb015 for Train set\n",
      "Processed mdb127 for Train set\n",
      "Processed mdb271 for Train set\n",
      "Processed mdb204 for Train set\n",
      "Processed mdb095 for Train set\n",
      "Processed mdb072 for Train set\n",
      "Processed mdb227 for Train set\n",
      "Processed mdb249 for Train set\n",
      "Processed mdb091 for Train set\n",
      "Processed mdb017 for Train set\n",
      "Processed mdb028 for Train set\n",
      "Processed mdb212 for Train set\n",
      "Processed mdb005 for Train set\n",
      "Processed mdb063 for Train set\n",
      "Processed mdb120 for Train set\n",
      "Processed mdb226 for Train set\n",
      "Processed mdb013 for Train set\n",
      "Processed mdb199 for Train set\n",
      "Processed mdb241 for Train set\n",
      "Processed mdb226 for Train set\n",
      "Processed mdb150 for Train set\n",
      "Processed mdb144 for Train set\n",
      "Processed mdb264 for Train set\n",
      "Processed mdb132 for Train set\n",
      "Processed mdb207 for Train set\n",
      "Processed mdb167 for Train set\n",
      "Processed mdb290 for Train set\n",
      "Processed mdb206 for Train set\n",
      "Processed mdb312 for Train set\n",
      "Processed mdb125 for Train set\n",
      "Processed mdb160 for Train set\n",
      "Processed mdb141 for Train set\n",
      "Processed mdb240 for Train set\n",
      "Processed mdb158 for Train set\n",
      "Processed mdb198 for Train set\n",
      "Processed mdb105 for Train set\n",
      "Processed mdb267 for Train set\n",
      "Processed mdb163 for Train set\n",
      "Processed mdb171 for Train set\n",
      "Processed mdb239 for Train set\n",
      "Processed mdb117 for Train set\n",
      "Processed mdb099 for Train set\n",
      "Processed mdb249 for Train set\n",
      "Processed mdb002 for Train set\n",
      "Processed mdb145 for Train set\n",
      "Processed mdb080 for Train set\n",
      "Processed mdb005 for Train set\n",
      "Processed mdb083 for Train set\n",
      "Processed mdb248 for Train set\n",
      "Processed mdb239 for Train set\n",
      "Processed mdb219 for Train set\n",
      "Processed mdb253 for Train set\n",
      "Processed mdb195 for Train set\n",
      "Processed mdb218 for Train set\n",
      "Processed mdb211 for Train set\n",
      "Processed mdb315 for Train set\n",
      "Processed mdb075 for Train set\n",
      "Processed mdb165 for Train set\n",
      "Processed mdb190 for Train set\n",
      "Processed mdb252 for Train set\n",
      "Processed mdb030 for Train set\n",
      "Processed mdb226 for Train set\n",
      "Processed mdb144 for Train set\n",
      "Processed mdb244 for Train set\n",
      "Processed mdb155 for Test set\n",
      "Processed mdb223 for Test set\n",
      "Processed mdb010 for Test set\n",
      "Processed mdb132 for Test set\n",
      "Processed mdb092 for Test set\n",
      "Processed mdb314 for Test set\n",
      "Processed mdb186 for Test set\n",
      "Processed mdb021 for Test set\n",
      "Processed mdb223 for Test set\n",
      "Processed mdb193 for Test set\n",
      "Processed mdb069 for Test set\n",
      "Processed mdb270 for Test set\n",
      "Processed mdb023 for Test set\n",
      "Processed mdb236 for Test set\n",
      "Processed mdb126 for Test set\n",
      "Processed mdb104 for Test set\n",
      "Processed mdb222 for Test set\n",
      "Processed mdb001 for Test set\n",
      "Processed mdb238 for Test set\n",
      "Processed mdb265 for Test set\n",
      "Processed mdb175 for Test set\n",
      "Processed mdb124 for Test set\n",
      "Processed mdb231 for Test set\n",
      "Processed mdb148 for Test set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def crop_and_save(img, x, y, radius, output_path):\n",
    "    h,w=img.shape\n",
    "    # 确保裁剪区域不超出图像边界\n",
    "    x = int(x)\n",
    "    y = w-int(y)\n",
    "    radius = int(radius)\n",
    "    x1 = max(x - radius, 0)\n",
    "    y1 = max(y - radius, 0)\n",
    "    x2 = min(x + radius, img.shape[1])\n",
    "    y2 = min(y + radius, img.shape[0])\n",
    "\n",
    "    # 裁剪图像\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "    cropped_img = cv2.normalize(cropped_img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "    # 保存裁剪后的图像\n",
    "    cv2.imwrite(output_path, cropped_img)\n",
    "\n",
    "\n",
    "# 定义路径\n",
    "TXT_PATH = '/Volumes/图图/MIAS/archive/Info.txt'\n",
    "PGM_PATH = '/Volumes/图图/MIAS/archive/all-mias'\n",
    "OUTPUT_BASE_PATH = '/Volumes/图图/MIAS/archive/cropped-classification'\n",
    "\n",
    "# 读取TXT文件\n",
    "with open(TXT_PATH, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# 跳过标题行\n",
    "lines = lines[1:]\n",
    "lines = [line for line in lines if len(line.split()) > 4]\n",
    "\n",
    "train_lines, test_lines = train_test_split(lines, test_size=0.2, random_state=42)\n",
    "\n",
    "def process_and_save(lines, set_type):\n",
    "    refnum_counter = {}\n",
    "    for line in lines:\n",
    "        # print(line)\n",
    "        parts = line.split()\n",
    "        refnum = parts[0]\n",
    "        # bg = parts[1]\n",
    "        cls = str(parts[2]).replace(' ','')\n",
    "        severity = str(parts[3]).replace(' ','')\n",
    "        x = parts[4]\n",
    "        y = parts[5]\n",
    "        radius = parts[6]\n",
    "        \n",
    "        if refnum in refnum_counter:\n",
    "            refnum_counter[refnum] += 1\n",
    "        else:\n",
    "            refnum_counter[refnum] = 1\n",
    "        refnum_with_suffix = f\"{refnum}_{refnum_counter[refnum]}\"\n",
    "\n",
    "        # 读取PGM文件\n",
    "        pgm_file = os.path.join(PGM_PATH, refnum + '.pgm')\n",
    "        if os.path.exists(pgm_file):\n",
    "            img = cv2.imread(pgm_file, cv2.IMREAD_GRAYSCALE)\n",
    "            # img = preprocess(img)\n",
    "            # img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "            # 创建输出目录\n",
    "            output_dir = os.path.join(OUTPUT_BASE_PATH, set_type, refnum_with_suffix)\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "\n",
    "            jpg_output_path = os.path.join(output_dir, 'img.jpg')\n",
    "            crop_and_save(img, x, y, radius, jpg_output_path)\n",
    "\n",
    "            # 保存标签为NumPy文件字典\n",
    "            info = {\n",
    "                # 'background': bg\n",
    "                'class': cls,\n",
    "                'severity': severity\n",
    "            }\n",
    "            npy_path = os.path.join(output_dir, 'info_dict.npy')\n",
    "            np.save(npy_path, info)\n",
    "\n",
    "            print(f\"Processed {refnum} for {set_type} set\")\n",
    "        else:\n",
    "            print(f\"PGM file for {refnum} not found.\")\n",
    "\n",
    "# 处理并保存训练集和测试集\n",
    "process_and_save(train_lines, 'Train')\n",
    "process_and_save(test_lines, 'Test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
